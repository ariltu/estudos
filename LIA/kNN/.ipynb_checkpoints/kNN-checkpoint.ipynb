{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial: implementando kNN em Python\n",
    "\n",
    "O algoritmo \"kNN\" (k-Nearest Neighbors ou k-vizinhos mais próximos) é fácil de entender e implementar, além de ser uma ferramenta poderosa!\n",
    "Quase parece ser simples demais para ser um algoritmo de *machine learning*. \n",
    "\n",
    "A ideia é a seguinte: \n",
    "\n",
    "*\"Se o que estou comendo parece pizza com borda de chocolate e tem borda de chocolate, então deve ser pizza com borda de chocolate!\"*\n",
    "\n",
    "Em outras palavras, para classificar uma coisa desconhecida, analisamos com o que essa coisa mais se parece, e fazemos uma média para chegar à conclusão!\n",
    "\n",
    "# Pegando a intuição\n",
    "\n",
    "Analise a imagem abaixo. Digamos que você quer descobrir se o misterioso círculo verde é na verdade um Triângulo Vermelho ou Quadrado Azul. O que você faria?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](src/knn.png)\n",
    "*Fonte: Wikipedia*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma opção seria pegar os três vizinhos mais próximos e adivinhar que o círculo verde é provavelmente um Triângulo Vermelho. Você poderia, ainda, expandir o circulo além e analisar os cinco vizinhos mais próximos para classificar (3 de 5 vizinhos mais próximos são Quadrados Azuis, então podemos adivinhar que o misterioso círculo verde é um Quadrado Azul quando k=5).\n",
    "\n",
    "E fim. Isso é **k-nearest neighbors**. Você pega os *k* vizinhos (ou dados) mais próximos e faz a média de seus valores se a variável for contínua (como preço de um produto) ou a moda se a variável for categórica (como Quadrado Azul vs Triângulo Vermelho)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definindo \"proximidade\": medidas de distância\n",
    "\n",
    "Como faz pra saber a distância entre uma instância e os \"vizinhos mais próximos\"? Como determinar matematicamente quais dos Quadrados Azuis e Triângulos Vermelhos estão mais próximos do círculo verde, especialmente se você não pode medir isso no \"olhômetro\"?\n",
    "\n",
    "O jeito mais direto é medir a distância euclidiana (geometricamente corresponde a uma linha reta). Outra forma seria a distância Manhattan, que faz alusão ao formato quadriculado da maior parte das ruas na ilha de Manhattan. Como essa forma é mais parecida com andar por quarteirões, é mais útil no cálculo de tarifas para motoristas de Uber, por exemplo.\n",
    "\n",
    "![distancias](src/distancias.png)\n",
    "*Linha verde = distância euclidiana. Linha azul = distância de Manhattan.*\n",
    "*Fonte: Wikipedia*\n",
    "\n",
    "Normalmente, você não precisa calcular qualquer distância na mão, porque basta uma rápida pesquisa no Google para encontrar funções prontas em bibliotecas como **NumPy** e **SciPy**. Mas de qualquer forma, talvez seja legal ver coisas da geometria do ensino médio sendo úteis para construir modelos de *Machine Learning*!\n",
    "\n",
    "Para pontos bidimensionais P(px, py) e Q(qx, qy), calculamos a distância assim:\n",
    "\n",
    "![distancia](src/distancia.svg)\n",
    "\n",
    "Isso pode ser generalizado para pontos de qualquer dimensão."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementando\n",
    "\n",
    "Esta implementação será específica para classificação (variável categórica) e demonstraremos usando o exemplo das plantas da flor Iris, que tem 3 espécies diferentes:\n",
    "- Iris setosa\n",
    "- Iris virginica\n",
    "- Iris versicolor\n",
    "\n",
    "![title](src/iris.png)\n",
    "*Fonte: UCI Machine Learning Repository*\n",
    "\n",
    "Iremos elaborar um modelo que irá fazer predições baseado em duas medidas para a sépala e para a pétala: a largura e comprimento. E o conjunto de dados é um conjunto padrão, em que a espécie é conhecida para todas as instâncias. Assim, podemos separar o conjunto em partes de treino e de teste e usar os resultados para medir a taxa de acerto. Nesse problema, uma boa taxa é acima de 90%, normalmente 96% ou mais."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparando os dados\n",
    "\n",
    "O primeiro passo é carregar os dados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.1, 3.5, 1.4, 0.2, Iris-setosa\n",
      "4.9, 3.0, 1.4, 0.2, Iris-setosa\n",
      "4.7, 3.2, 1.3, 0.2, Iris-setosa\n",
      "4.6, 3.1, 1.5, 0.2, Iris-setosa\n",
      "5.0, 3.6, 1.4, 0.2, Iris-setosa\n",
      "5.4, 3.9, 1.7, 0.4, Iris-setosa\n",
      "4.6, 3.4, 1.4, 0.3, Iris-setosa\n",
      "5.0, 3.4, 1.5, 0.2, Iris-setosa\n",
      "4.4, 2.9, 1.4, 0.2, Iris-setosa\n",
      "4.9, 3.1, 1.5, 0.1, Iris-setosa\n",
      "5.4, 3.7, 1.5, 0.2, Iris-setosa\n",
      "4.8, 3.4, 1.6, 0.2, Iris-setosa\n",
      "4.8, 3.0, 1.4, 0.1, Iris-setosa\n",
      "4.3, 3.0, 1.1, 0.1, Iris-setosa\n",
      "5.8, 4.0, 1.2, 0.2, Iris-setosa\n",
      "5.7, 4.4, 1.5, 0.4, Iris-setosa\n",
      "5.4, 3.9, 1.3, 0.4, Iris-setosa\n",
      "5.1, 3.5, 1.4, 0.3, Iris-setosa\n",
      "5.7, 3.8, 1.7, 0.3, Iris-setosa\n",
      "5.1, 3.8, 1.5, 0.3, Iris-setosa\n",
      "5.4, 3.4, 1.7, 0.2, Iris-setosa\n",
      "5.1, 3.7, 1.5, 0.4, Iris-setosa\n",
      "4.6, 3.6, 1.0, 0.2, Iris-setosa\n",
      "5.1, 3.3, 1.7, 0.5, Iris-setosa\n",
      "4.8, 3.4, 1.9, 0.2, Iris-setosa\n",
      "5.0, 3.0, 1.6, 0.2, Iris-setosa\n",
      "5.0, 3.4, 1.6, 0.4, Iris-setosa\n",
      "5.2, 3.5, 1.5, 0.2, Iris-setosa\n",
      "5.2, 3.4, 1.4, 0.2, Iris-setosa\n",
      "4.7, 3.2, 1.6, 0.2, Iris-setosa\n",
      "4.8, 3.1, 1.6, 0.2, Iris-setosa\n",
      "5.4, 3.4, 1.5, 0.4, Iris-setosa\n",
      "5.2, 4.1, 1.5, 0.1, Iris-setosa\n",
      "5.5, 4.2, 1.4, 0.2, Iris-setosa\n",
      "4.9, 3.1, 1.5, 0.1, Iris-setosa\n",
      "5.0, 3.2, 1.2, 0.2, Iris-setosa\n",
      "5.5, 3.5, 1.3, 0.2, Iris-setosa\n",
      "4.9, 3.1, 1.5, 0.1, Iris-setosa\n",
      "4.4, 3.0, 1.3, 0.2, Iris-setosa\n",
      "5.1, 3.4, 1.5, 0.2, Iris-setosa\n",
      "5.0, 3.5, 1.3, 0.3, Iris-setosa\n",
      "4.5, 2.3, 1.3, 0.3, Iris-setosa\n",
      "4.4, 3.2, 1.3, 0.2, Iris-setosa\n",
      "5.0, 3.5, 1.6, 0.6, Iris-setosa\n",
      "5.1, 3.8, 1.9, 0.4, Iris-setosa\n",
      "4.8, 3.0, 1.4, 0.3, Iris-setosa\n",
      "5.1, 3.8, 1.6, 0.2, Iris-setosa\n",
      "4.6, 3.2, 1.4, 0.2, Iris-setosa\n",
      "5.3, 3.7, 1.5, 0.2, Iris-setosa\n",
      "5.0, 3.3, 1.4, 0.2, Iris-setosa\n",
      "7.0, 3.2, 4.7, 1.4, Iris-versicolor\n",
      "6.4, 3.2, 4.5, 1.5, Iris-versicolor\n",
      "6.9, 3.1, 4.9, 1.5, Iris-versicolor\n",
      "5.5, 2.3, 4.0, 1.3, Iris-versicolor\n",
      "6.5, 2.8, 4.6, 1.5, Iris-versicolor\n",
      "5.7, 2.8, 4.5, 1.3, Iris-versicolor\n",
      "6.3, 3.3, 4.7, 1.6, Iris-versicolor\n",
      "4.9, 2.4, 3.3, 1.0, Iris-versicolor\n",
      "6.6, 2.9, 4.6, 1.3, Iris-versicolor\n",
      "5.2, 2.7, 3.9, 1.4, Iris-versicolor\n",
      "5.0, 2.0, 3.5, 1.0, Iris-versicolor\n",
      "5.9, 3.0, 4.2, 1.5, Iris-versicolor\n",
      "6.0, 2.2, 4.0, 1.0, Iris-versicolor\n",
      "6.1, 2.9, 4.7, 1.4, Iris-versicolor\n",
      "5.6, 2.9, 3.6, 1.3, Iris-versicolor\n",
      "6.7, 3.1, 4.4, 1.4, Iris-versicolor\n",
      "5.6, 3.0, 4.5, 1.5, Iris-versicolor\n",
      "5.8, 2.7, 4.1, 1.0, Iris-versicolor\n",
      "6.2, 2.2, 4.5, 1.5, Iris-versicolor\n",
      "5.6, 2.5, 3.9, 1.1, Iris-versicolor\n",
      "5.9, 3.2, 4.8, 1.8, Iris-versicolor\n",
      "6.1, 2.8, 4.0, 1.3, Iris-versicolor\n",
      "6.3, 2.5, 4.9, 1.5, Iris-versicolor\n",
      "6.1, 2.8, 4.7, 1.2, Iris-versicolor\n",
      "6.4, 2.9, 4.3, 1.3, Iris-versicolor\n",
      "6.6, 3.0, 4.4, 1.4, Iris-versicolor\n",
      "6.8, 2.8, 4.8, 1.4, Iris-versicolor\n",
      "6.7, 3.0, 5.0, 1.7, Iris-versicolor\n",
      "6.0, 2.9, 4.5, 1.5, Iris-versicolor\n",
      "5.7, 2.6, 3.5, 1.0, Iris-versicolor\n",
      "5.5, 2.4, 3.8, 1.1, Iris-versicolor\n",
      "5.5, 2.4, 3.7, 1.0, Iris-versicolor\n",
      "5.8, 2.7, 3.9, 1.2, Iris-versicolor\n",
      "6.0, 2.7, 5.1, 1.6, Iris-versicolor\n",
      "5.4, 3.0, 4.5, 1.5, Iris-versicolor\n",
      "6.0, 3.4, 4.5, 1.6, Iris-versicolor\n",
      "6.7, 3.1, 4.7, 1.5, Iris-versicolor\n",
      "6.3, 2.3, 4.4, 1.3, Iris-versicolor\n",
      "5.6, 3.0, 4.1, 1.3, Iris-versicolor\n",
      "5.5, 2.5, 4.0, 1.3, Iris-versicolor\n",
      "5.5, 2.6, 4.4, 1.2, Iris-versicolor\n",
      "6.1, 3.0, 4.6, 1.4, Iris-versicolor\n",
      "5.8, 2.6, 4.0, 1.2, Iris-versicolor\n",
      "5.0, 2.3, 3.3, 1.0, Iris-versicolor\n",
      "5.6, 2.7, 4.2, 1.3, Iris-versicolor\n",
      "5.7, 3.0, 4.2, 1.2, Iris-versicolor\n",
      "5.7, 2.9, 4.2, 1.3, Iris-versicolor\n",
      "6.2, 2.9, 4.3, 1.3, Iris-versicolor\n",
      "5.1, 2.5, 3.0, 1.1, Iris-versicolor\n",
      "5.7, 2.8, 4.1, 1.3, Iris-versicolor\n",
      "6.3, 3.3, 6.0, 2.5, Iris-virginica\n",
      "5.8, 2.7, 5.1, 1.9, Iris-virginica\n",
      "7.1, 3.0, 5.9, 2.1, Iris-virginica\n",
      "6.3, 2.9, 5.6, 1.8, Iris-virginica\n",
      "6.5, 3.0, 5.8, 2.2, Iris-virginica\n",
      "7.6, 3.0, 6.6, 2.1, Iris-virginica\n",
      "4.9, 2.5, 4.5, 1.7, Iris-virginica\n",
      "7.3, 2.9, 6.3, 1.8, Iris-virginica\n",
      "6.7, 2.5, 5.8, 1.8, Iris-virginica\n",
      "7.2, 3.6, 6.1, 2.5, Iris-virginica\n",
      "6.5, 3.2, 5.1, 2.0, Iris-virginica\n",
      "6.4, 2.7, 5.3, 1.9, Iris-virginica\n",
      "6.8, 3.0, 5.5, 2.1, Iris-virginica\n",
      "5.7, 2.5, 5.0, 2.0, Iris-virginica\n",
      "5.8, 2.8, 5.1, 2.4, Iris-virginica\n",
      "6.4, 3.2, 5.3, 2.3, Iris-virginica\n",
      "6.5, 3.0, 5.5, 1.8, Iris-virginica\n",
      "7.7, 3.8, 6.7, 2.2, Iris-virginica\n",
      "7.7, 2.6, 6.9, 2.3, Iris-virginica\n",
      "6.0, 2.2, 5.0, 1.5, Iris-virginica\n",
      "6.9, 3.2, 5.7, 2.3, Iris-virginica\n",
      "5.6, 2.8, 4.9, 2.0, Iris-virginica\n",
      "7.7, 2.8, 6.7, 2.0, Iris-virginica\n",
      "6.3, 2.7, 4.9, 1.8, Iris-virginica\n",
      "6.7, 3.3, 5.7, 2.1, Iris-virginica\n",
      "7.2, 3.2, 6.0, 1.8, Iris-virginica\n",
      "6.2, 2.8, 4.8, 1.8, Iris-virginica\n",
      "6.1, 3.0, 4.9, 1.8, Iris-virginica\n",
      "6.4, 2.8, 5.6, 2.1, Iris-virginica\n",
      "7.2, 3.0, 5.8, 1.6, Iris-virginica\n",
      "7.4, 2.8, 6.1, 1.9, Iris-virginica\n",
      "7.9, 3.8, 6.4, 2.0, Iris-virginica\n",
      "6.4, 2.8, 5.6, 2.2, Iris-virginica\n",
      "6.3, 2.8, 5.1, 1.5, Iris-virginica\n",
      "6.1, 2.6, 5.6, 1.4, Iris-virginica\n",
      "7.7, 3.0, 6.1, 2.3, Iris-virginica\n",
      "6.3, 3.4, 5.6, 2.4, Iris-virginica\n",
      "6.4, 3.1, 5.5, 1.8, Iris-virginica\n",
      "6.0, 3.0, 4.8, 1.8, Iris-virginica\n",
      "6.9, 3.1, 5.4, 2.1, Iris-virginica\n",
      "6.7, 3.1, 5.6, 2.4, Iris-virginica\n",
      "6.9, 3.1, 5.1, 2.3, Iris-virginica\n",
      "5.8, 2.7, 5.1, 1.9, Iris-virginica\n",
      "6.8, 3.2, 5.9, 2.3, Iris-virginica\n",
      "6.7, 3.3, 5.7, 2.5, Iris-virginica\n",
      "6.7, 3.0, 5.2, 2.3, Iris-virginica\n",
      "6.3, 2.5, 5.0, 1.9, Iris-virginica\n",
      "6.5, 3.0, 5.2, 2.0, Iris-virginica\n",
      "6.2, 3.4, 5.4, 2.3, Iris-virginica\n",
      "5.9, 3.0, 5.1, 1.8, Iris-virginica\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "with open('src/iris.csv', 'rb') as arquivocsv:\n",
    "    linhas = csv.reader(arquivocsv)\n",
    "    for linha in linhas:\n",
    "        print ', '.join(linha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em seguida, vamos dividir o conjunto em parte de treino que o kNN pode usar para fazer predições e em parte de teste que usaremos para avaliar a taxa de acerto do modelo.\n",
    "\n",
    "Primeiro, convertemos as medidas das flores que foram lidas como strings em números que podemos usar para nosso trabalho. Depois, dividimos (cortamos) o conjunto aleatoriamente em uma propoção de 70/30.\n",
    "\n",
    "Juntamos tudo isso em uma função de nome *carregarDados* que carrega um CSV com o nome fornecido e o divide aleatoriamente usando a proporção fornecida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "def carregarDados(nome_arquivo, corte, conjunto_treino=[] , conjunto_teste=[]):\n",
    "\twith open(nome_arquivo, 'rb') as arquivo_csv:\n",
    "\t    linhas = csv.reader(arquivo_csv)\n",
    "\t    dataset = list(linhas)\n",
    "\t    for x in range(len(dataset)-1):\n",
    "\t        for y in range(4):\n",
    "\t            dataset[x][y] = float(dataset[x][y])\n",
    "\t        if random.random() < corte:\n",
    "\t            conjunto_treino.append(dataset[x])\n",
    "\t        else:\n",
    "\t            conjunto_teste.append(dataset[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos testar essa função assim:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 95\n",
      "Test: 55\n"
     ]
    }
   ],
   "source": [
    "conjunto_treino=[]\n",
    "conjunto_teste=[]\n",
    "carregarDados('src/iris.csv', 0.7, conjunto_treino, conjunto_teste)\n",
    "print 'Train: ' + repr(len(conjunto_treino))\n",
    "print 'Test: ' + repr(len(conjunto_teste))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proximidade\n",
    "\n",
    "A fim de fazer predições, vamos calcular a proximidade ou similaridade entre duas instâncias quaisquer. Precisamos disso para poder localizar os K dados mais similares no conjunto de treino para, então, fazer a predição.\n",
    "\n",
    "Como as quatro medidas das flores já são numéricas e estão na mesma unidade de medida, podemos usar a distância euclidiana diretamente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "def distancia_euclidiana(instancia1, instancia2, tamanho):\n",
    "\tdistancia = 0\n",
    "\tfor x in range(tamanho):\n",
    "\t\tdistancia += pow((instancia1[x] - instancia2[x]), 2)\n",
    "\treturn math.sqrt(distancia)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos testar essa função com dados inventados:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distancia: 4.0\n"
     ]
    }
   ],
   "source": [
    "dado1 = [2, 2, 2, 2, 'a']\n",
    "dado2 = [4, 4, 4, 4, 'b']\n",
    "distancia = distancia_euclidiana(dado1, dado2, 4)\n",
    "print 'Distancia: ' + repr(distancia)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vizinhos\n",
    "\n",
    "\n",
    "Agora que tenho uma ferramenta pra dizer a similaridade, podemos usá-la para coletar as k instâncias mais parecidas com uma dada instância desconhecida.\n",
    "\n",
    "Esse processo é simplesmente calcular a distância entre a instância desconhecida e todas as outras conhecidas, e pegar aquelas com as menores distâncias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import operator \n",
    "def localizar_vizinhos(conjunto_treino, instancia_teste, k):\n",
    "    distancias = []\n",
    "    tamanho = len(instancia_teste)-1\n",
    "    for x in range(len(conjunto_treino)):\n",
    "        dist = distancia_euclidiana(instancia_teste, conjunto_treino[x], tamanho)\n",
    "        distancias.append((conjunto_treino[x], dist))\n",
    "    distancias.sort(key=operator.itemgetter(1))\n",
    "    vizinhos = []\n",
    "    for x in range(k):\n",
    "        vizinhos.append(distancias[x][0])\n",
    "    return vizinhos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos testar assim:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4, 4, 4, 4, 'b']]\n"
     ]
    }
   ],
   "source": [
    "conjuntoTreino = [[2, 2, 2, 2, 'a'], [4, 4, 4, 4, 'b']]\n",
    "instancia_teste = [5, 5, 5, 5]\n",
    "k = 1\n",
    "vizinhos = localizar_vizinhos(conjuntoTreino, instancia_teste, k)\n",
    "print(vizinhos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resposta\n",
    "\n",
    "\n",
    "Uma vez que localizamos os vizinhos mais próximos, o próximo passo é delegar uma resposta prevista com base nesses vizinhos. Podemos fazer isso ao deixar cada vizinho \"votar\" por sua classe atribuída, e pegar a classe com mais votos como sendo a predição.\n",
    "\n",
    "Abaixo, a função pega a resposta votada pela maioria por um número de vizinhos (assumindo que a classe é o último atribudo de cada vizinho):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import operator\n",
    "def calcularResposta(vizinhos):\n",
    "    votos = {}\n",
    "    for x in range(len(vizinhos)):\n",
    "        resposta = vizinhos[x][-1]\n",
    "        if resposta in votos:\n",
    "            votos[resposta] += 1\n",
    "        else:\n",
    "            votos[resposta] = 1\n",
    "    votosOrdenados = sorted(votos.iteritems(), key=operator.itemgetter(1), reverse=True)\n",
    "    return votosOrdenados[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos testar essa função com alguns vizinhos assim:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n"
     ]
    }
   ],
   "source": [
    "vizinhos = [[1,1,1,1,'a'], [2,2,2,2,'a'], [3,3,3,3,'b']]\n",
    "resposta = calcularResposta(vizinhos)\n",
    "print(resposta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taxa de acerto\n",
    "\n",
    "\n",
    "Temos todos os pedaços do algoritmo feitos. Uma preocupação a essa altura é como avaliar a taxa de acerto de suas predições. E um jeito fácil de fazer isso é encontrar a proporção do número total de predições corretas em relação a todas as predições feitas.\n",
    "\n",
    "Abaixo, a função conta o total de respostas certas e retorna a taxa de acerto como uma porcentagem de classificações corretas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calcularAcerto(conjunto_teste, respostas):\n",
    "    corretos = 0\n",
    "    for x in range(len(conjunto_teste)):\n",
    "        if conjunto_teste[x][-1] is respostas[x]:\n",
    "            corretos += 1\n",
    "    return (corretos/float(len(conjunto_teste))) * 100.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos testar essa função com dados e predições fictícias:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66.6666666667\n"
     ]
    }
   ],
   "source": [
    "conjunto_teste = [[1,1,1,1,'a'], [2,2,2,2,'a'], [3,3,3,3,'b']]\n",
    "respostas = ['a', 'a', 'a']\n",
    "acerto = calcularAcerto(conjunto_teste, respostas)\n",
    "print(acerto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Finalizando o algoritmo\n",
    "\n",
    "Agora temos todas as peças do algoritmo em mãos, e podemos encaixá-las juntas na função main:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conjunto de treino: 106\n",
      "Conjunto de teste: 44\n",
      "> previsto='Iris-setosa', real='Iris-setosa'\n",
      "> previsto='Iris-setosa', real='Iris-setosa'\n",
      "> previsto='Iris-setosa', real='Iris-setosa'\n",
      "> previsto='Iris-setosa', real='Iris-setosa'\n",
      "> previsto='Iris-setosa', real='Iris-setosa'\n",
      "> previsto='Iris-setosa', real='Iris-setosa'\n",
      "> previsto='Iris-setosa', real='Iris-setosa'\n",
      "> previsto='Iris-setosa', real='Iris-setosa'\n",
      "> previsto='Iris-setosa', real='Iris-setosa'\n",
      "> previsto='Iris-setosa', real='Iris-setosa'\n",
      "> previsto='Iris-setosa', real='Iris-setosa'\n",
      "> previsto='Iris-setosa', real='Iris-setosa'\n",
      "> previsto='Iris-setosa', real='Iris-setosa'\n",
      "> previsto='Iris-setosa', real='Iris-setosa'\n",
      "> previsto='Iris-setosa', real='Iris-setosa'\n",
      "> previsto='Iris-setosa', real='Iris-setosa'\n",
      "> previsto='Iris-versicolor', real='Iris-versicolor'\n",
      "> previsto='Iris-versicolor', real='Iris-versicolor'\n",
      "> previsto='Iris-versicolor', real='Iris-versicolor'\n",
      "> previsto='Iris-versicolor', real='Iris-versicolor'\n",
      "> previsto='Iris-versicolor', real='Iris-versicolor'\n",
      "> previsto='Iris-versicolor', real='Iris-versicolor'\n",
      "> previsto='Iris-virginica', real='Iris-versicolor'\n",
      "> previsto='Iris-versicolor', real='Iris-versicolor'\n",
      "> previsto='Iris-versicolor', real='Iris-versicolor'\n",
      "> previsto='Iris-versicolor', real='Iris-versicolor'\n",
      "> previsto='Iris-versicolor', real='Iris-versicolor'\n",
      "> previsto='Iris-versicolor', real='Iris-versicolor'\n",
      "> previsto='Iris-versicolor', real='Iris-versicolor'\n",
      "> previsto='Iris-versicolor', real='Iris-versicolor'\n",
      "> previsto='Iris-versicolor', real='Iris-versicolor'\n",
      "> previsto='Iris-versicolor', real='Iris-versicolor'\n",
      "> previsto='Iris-virginica', real='Iris-virginica'\n",
      "> previsto='Iris-virginica', real='Iris-virginica'\n",
      "> previsto='Iris-virginica', real='Iris-virginica'\n",
      "> previsto='Iris-virginica', real='Iris-virginica'\n",
      "> previsto='Iris-virginica', real='Iris-virginica'\n",
      "> previsto='Iris-virginica', real='Iris-virginica'\n",
      "> previsto='Iris-virginica', real='Iris-virginica'\n",
      "> previsto='Iris-virginica', real='Iris-virginica'\n",
      "> previsto='Iris-virginica', real='Iris-virginica'\n",
      "> previsto='Iris-virginica', real='Iris-virginica'\n",
      "> previsto='Iris-virginica', real='Iris-virginica'\n",
      "> previsto='Iris-virginica', real='Iris-virginica'\n",
      "Taxa de acerto: 97.72727272727273%\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "with open('src/iris.csv', 'rb') as arquivocsv:\n",
    "    linhas = csv.reader(arquivocsv)\n",
    "\n",
    "import random\n",
    "def carregarDados(nome_arquivo, corte, conjunto_treino=[] , conjunto_teste=[]):\n",
    "    with open(nome_arquivo, 'rb') as arquivo_csv:\n",
    "        linhas = csv.reader(arquivo_csv)\n",
    "        dataset = list(linhas)\n",
    "        for x in range(len(dataset)-1):\n",
    "\t        for y in range(4):\n",
    "\t            dataset[x][y] = float(dataset[x][y])\n",
    "\t        if random.random() < corte:\n",
    "\t            conjunto_treino.append(dataset[x])\n",
    "\t        else:\n",
    "\t            conjunto_teste.append(dataset[x])\n",
    "\n",
    "import math\n",
    "def distancia_euclidiana(instancia1, instancia2, tamanho):\n",
    "\tdistancia = 0\n",
    "\tfor x in range(tamanho):\n",
    "\t\tdistancia += pow((instancia1[x] - instancia2[x]), 2)\n",
    "\treturn math.sqrt(distancia)\n",
    "\n",
    "import operator\n",
    "def localizar_vizinhos(conjunto_treino, instancia_teste, k):\n",
    "    distancias = []\n",
    "    tamanho = len(instancia_teste)-1\n",
    "    for x in range(len(conjunto_treino)):\n",
    "        dist = distancia_euclidiana(instancia_teste, conjunto_treino[x], tamanho)\n",
    "        distancias.append((conjunto_treino[x], dist))\n",
    "    distancias.sort(key=operator.itemgetter(1))\n",
    "    vizinhos = []\n",
    "    for x in range(k):\n",
    "        vizinhos.append(distancias[x][0])\n",
    "    return vizinhos\n",
    "\n",
    "import operator\n",
    "def calcularResposta(vizinhos):\n",
    "    votos = {}\n",
    "    for x in range(len(vizinhos)):\n",
    "        resposta = vizinhos[x][-1]\n",
    "        if resposta in votos:\n",
    "            votos[resposta] += 1\n",
    "        else:\n",
    "            votos[resposta] = 1\n",
    "    votosOrdenados = sorted(votos.iteritems(), key=operator.itemgetter(1), reverse=True)\n",
    "    return votosOrdenados[0][0]\n",
    "\n",
    "def calcularAcerto(conjunto_teste, respostas):\n",
    "    corretos = 0\n",
    "    for x in range(len(conjunto_teste)):\n",
    "        if conjunto_teste[x][-1] == respostas[x]:\n",
    "            corretos += 1\n",
    "    return (corretos/float(len(conjunto_teste))) * 100.0\n",
    "\n",
    "\n",
    "def main():\n",
    "    # prerarar os dados\n",
    "    conjunto_treino = []\n",
    "    conjunto_teste = []\n",
    "    corte = 0.7\n",
    "    carregarDados('src/iris.csv', corte, conjunto_treino, conjunto_teste)\n",
    "    print 'Conjunto de treino: ' +repr(len(conjunto_treino))\n",
    "    print 'Conjunto de teste: ' +repr(len(conjunto_teste))\n",
    "    #gerar respostas\n",
    "    respostas = []\n",
    "    k = 3\n",
    "    for x in range(len(conjunto_teste)):\n",
    "        vizinhos = localizar_vizinhos(conjunto_treino, conjunto_teste[x], k)\n",
    "        resultado = calcularResposta(vizinhos)\n",
    "        respostas.append(resultado)\n",
    "        print('> previsto=' + repr(resultado) + ', real=' + repr(conjunto_teste[x][-1]))\n",
    "    acerto = calcularAcerto(conjunto_teste, respostas)\n",
    "    print('Taxa de acerto: ' + repr(acerto) + '%')\n",
    "\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sobre o kNN\n",
    "\n",
    "O fato de o kNN não depender de uma função paramétrica pré-definida *f(X)* relacionando uma classe *Y* com um dado *X* o torna adequado para situações em que a relação entre os atributos de *X* é muito complexa para ser expressa através de um simples modelo linear. \n",
    "\n",
    "O kNN pertence à família dos algoritmos baseados em instância, com aprendizado competitivo e *lazy learning* (\"aprendizado preguiçoso\").\n",
    "\n",
    "Algoritmo baseado en instância é aquele que modela um problema usando instâncias dos dados a fim de decidir sua predição. O kNN é um exemplo extremo disso, porque o seu modelo consiste de, simplesmente, todas as instâncias do seu conjunto de dados.\n",
    "\n",
    "Aprendizado competitivo porque, internamente, há a competição entre os elementos do conjunto: somente aquelas instâncias mais similares \"vencem\" a votação ao classificar uma instância nunca vista antes.\n",
    "\n",
    "Lazy learning, ou aprendizado preguiçoso, se refere ao fato de que o kNN não gera um modelo propriamente dito até a hora em que lhe é pedido para fazer uma predição. É claro: toda vez que pedimos uma resposta ao algoritmo, ele busca, dentre todo o conjunto de dados que foi fornecido, aqueles mais similares. Sempre. No último segundo. (*preguiçoso*)\n",
    "\n",
    "Uma desvantagem do kNN é que ele pode ser bastante custoso computacionalmente, porque ele sempre repete as mesmas pesquisas dentro de conjuntos de treino maiores. Contudo, ele é poderoso porque não assume nenhum pressuposto sobre os dados. Isso porque ele não gera um modelo no formato de uma função (linear, por exemplo). Assim, ele é considerado um modelo não-paramétrico.\n",
    "\n",
    "### Ajustando o valor de K\n",
    "\n",
    "Para tentar aumentar a taxa de acerto, podemos tentar variar o valor de K e ver no que dá.\n",
    "\n",
    "Colocar valores pequenos de K pode tornar o modelo \"ingênuo\", pois ele toma suas decisões tomando como base poucas informações, ou pouca experiência. Porém, assim o modelo também fica mais flexível.\n",
    "\n",
    "Colocar valores maiores de K pode tornar o modelo mais robusto (menos ingênuo), e ajuda a evitar um fenômeno conhecido como \"[overfitting](https://pt.wikipedia.org/wiki/Sobreajuste)\". Porém, assim o modelo pode ficar muito inflexível. Por exemplo: se escolhermos o tamanho total do conjunto de dados como sendo o valor de K, o modelo vai simplesmente ver qual é a classe mais comum dentro do conjunto, e atribuir essa classe para *tudo o que vier depois*.\n",
    "\n",
    "Portanto, o melhor é procurar um ponto de equilíbrio para balancear as vantagens e desvantagens entre ingenuidade e experiência."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
